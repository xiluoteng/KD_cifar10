{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faf72b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model import Resnet\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "import numpy as np\n",
    "from torchvision.transforms import Compose, RandomHorizontalFlip, RandomGrayscale, ToTensor, Normalize\n",
    "from torchsummary import summary\n",
    "from torch.optim import Adam\n",
    "from torch.nn import MSELoss, KLDivLoss\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa55cd5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1e77c9242b0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainBS = 64\n",
    "TestBS = 64\n",
    "Learning_Rate = 0.001\n",
    "Random_Seed = np.random.uniform()\n",
    "torch.manual_seed(Random_Seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0095355b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "Train_Data = DataLoader(dataset = CIFAR10(train = True,\n",
    "                                          root = '/data/',\n",
    "                                          download = True,\n",
    "                                          transform = Compose([RandomHorizontalFlip(),\n",
    "                                                               RandomGrayscale(),\n",
    "                                                               ToTensor(),\n",
    "                                                               Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])),\n",
    "                       batch_size = TrainBS,\n",
    "                       shuffle = True)\n",
    "Test_Data = DataLoader(dataset = CIFAR10(train = False,\n",
    "                                         root = '/data/',\n",
    "                                         download = True,\n",
    "                                         transform = Compose([ToTensor(),\n",
    "                                                              Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])),\n",
    "                       batch_size = TestBS,\n",
    "                       shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4736f68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Resize-1          [-1, 3, 224, 224]               0\n",
      "            Conv2d-2         [-1, 64, 112, 112]           9,472\n",
      "       BatchNorm2d-3         [-1, 64, 112, 112]             128\n",
      "              ReLU-4         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-5           [-1, 64, 56, 56]               0\n",
      "            Conv2d-6           [-1, 64, 56, 56]          36,928\n",
      "       BatchNorm2d-7           [-1, 64, 56, 56]             128\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,928\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "           Conv2d-10           [-1, 64, 56, 56]          36,928\n",
      "      BatchNorm2d-11           [-1, 64, 56, 56]             128\n",
      "      Basic_Block-12           [-1, 64, 56, 56]               0\n",
      "           Conv2d-13           [-1, 64, 56, 56]          36,928\n",
      "      BatchNorm2d-14           [-1, 64, 56, 56]             128\n",
      "           Conv2d-15           [-1, 64, 56, 56]          36,928\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "      Basic_Block-17           [-1, 64, 56, 56]               0\n",
      "           Conv2d-18          [-1, 128, 28, 28]          73,856\n",
      "      BatchNorm2d-19          [-1, 128, 28, 28]             256\n",
      "           Conv2d-20          [-1, 128, 28, 28]          73,856\n",
      "      BatchNorm2d-21          [-1, 128, 28, 28]             256\n",
      "           Conv2d-22          [-1, 128, 28, 28]         147,584\n",
      "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
      "      Basic_Block-24          [-1, 128, 28, 28]               0\n",
      "           Conv2d-25          [-1, 128, 28, 28]         147,584\n",
      "      BatchNorm2d-26          [-1, 128, 28, 28]             256\n",
      "           Conv2d-27          [-1, 128, 28, 28]         147,584\n",
      "      BatchNorm2d-28          [-1, 128, 28, 28]             256\n",
      "      Basic_Block-29          [-1, 128, 28, 28]               0\n",
      "           Conv2d-30          [-1, 256, 14, 14]         295,168\n",
      "      BatchNorm2d-31          [-1, 256, 14, 14]             512\n",
      "           Conv2d-32          [-1, 256, 14, 14]         295,168\n",
      "      BatchNorm2d-33          [-1, 256, 14, 14]             512\n",
      "           Conv2d-34          [-1, 256, 14, 14]         590,080\n",
      "      BatchNorm2d-35          [-1, 256, 14, 14]             512\n",
      "      Basic_Block-36          [-1, 256, 14, 14]               0\n",
      "           Conv2d-37          [-1, 256, 14, 14]         590,080\n",
      "      BatchNorm2d-38          [-1, 256, 14, 14]             512\n",
      "           Conv2d-39          [-1, 256, 14, 14]         590,080\n",
      "      BatchNorm2d-40          [-1, 256, 14, 14]             512\n",
      "      Basic_Block-41          [-1, 256, 14, 14]               0\n",
      "           Conv2d-42            [-1, 512, 7, 7]       1,180,160\n",
      "      BatchNorm2d-43            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-44            [-1, 512, 7, 7]       1,180,160\n",
      "      BatchNorm2d-45            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-46            [-1, 512, 7, 7]       2,359,808\n",
      "      BatchNorm2d-47            [-1, 512, 7, 7]           1,024\n",
      "      Basic_Block-48            [-1, 512, 7, 7]               0\n",
      "           Conv2d-49            [-1, 512, 7, 7]       2,359,808\n",
      "      BatchNorm2d-50            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-51            [-1, 512, 7, 7]       2,359,808\n",
      "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
      "      Basic_Block-53            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-54            [-1, 512, 1, 1]               0\n",
      "           Linear-55                   [-1, 10]           5,130\n",
      "          Softmax-56                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 12,599,754\n",
      "Trainable params: 12,599,754\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 55.51\n",
      "Params size (MB): 48.06\n",
      "Estimated Total Size (MB): 104.15\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "Network = Resnet(34)\n",
    "summary(Network, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c29540",
   "metadata": {},
   "outputs": [],
   "source": [
    "Teacher_Network = resnet(34)\n",
    "Network.load_state_dict(torch.load('KD-resnet.pth'))\n",
    "\n",
    "Student_Network = Resnet(18)\n",
    "optimizer = Adam(params = Student_Network.parameters(), lr = Learning_Rate)  \n",
    "Loss_Function = MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be85a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "KD_temp = 1\n",
    "Soft_target_Loss = MSELoss()\n",
    "alpha = 0.5\n",
    "Hard_target_Loss = KLDivLoss(reduction=\"batchmean\")\n",
    "Beta = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d84810",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "for epoch in range(1,epochs + 1):\n",
    "    for data, target in tqdm(enumerate(Train_Data)):\n",
    "        Teacher_Pred = Teacher_Network(data)\n",
    "        Student_Pred = Student_Network(data)\n",
    "        Distill_Loss = Hard_target_Loss(Student_Pred / KD_temp, Teacher_Pred / KD_temp)\n",
    "        Student_Loss = Soft_target_Loss(Student_Pred, target)\n",
    "        Loss = alpha * Distill_Loss + Beta * Student_Loss\n",
    "        Loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_loss += Loss\n",
    "        correct += target.eq(Student_Network.data).sum()\n",
    "    print('Epoch:{}\\t Loss:{:.6f}\\t Acc:{:.1f}'.format(\n",
    "        epoch, avg_loss/len(Train_Data), 100.*correct/len(Train_Data.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bfc557",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
